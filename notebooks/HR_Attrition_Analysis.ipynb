{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# HR Analytics - Employee Attrition Prediction\n",
                "\n",
                "## ðŸ“Œ Project Context\n",
                "Employee attrition is a major concern for organizations as it leads to high costs of recruitment, training, and loss of institutional knowledge. This project aims to analyze employee data and build multiple machine learning models to predict who might leave and understand the key drivers behind these decisions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Model Selection & Evaluation\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
                "\n",
                "# Advanced Models\n",
                "try:\n",
                "    from xgboost import XGBClassifier\n",
                "except ImportError:\n",
                "    print(\"XGBoost not installed. Please install it using 'pip install xgboost'\")\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "sns.set_style('whitegrid')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_excel('../data/hr_analytics.xlsx')\n",
                "print(f\"Dataset Shape: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Exploratory Data Analysis (EDA)\n",
                "Understanding the distribution of features and their relationship with the target variable `left`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Target Variable Distribution\n",
                "plt.figure(figsize=(6, 4))\n",
                "sns.countplot(x='left', data=df, palette='viridis')\n",
                "plt.title('Distribution of Employee Attrition (0 = Stayed, 1 = Left)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation Heatmap\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
                "plt.title('Feature Correlation Heatmap')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Attrition by Salary Level\n",
                "plt.figure(figsize=(8, 5))\n",
                "sns.countplot(x='salary', hue='left', data=df, palette='magma')\n",
                "plt.title('Attrition vs Salary Level')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Attrition by Department\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.countplot(y='Department', hue='left', data=df, palette='Set2')\n",
                "plt.title('Attrition vs Department')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Satisfaction Level Distribution\n",
                "plt.figure(figsize=(8, 5))\n",
                "sns.histplot(x='satisfaction_level', hue='left', data=df, kde=True, palette='Set1')\n",
                "plt.title('Satisfaction Level vs Attrition')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Preprocessing\n",
                "Converting categorical columns to dummy variables and splitting the data into training and testing sets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert categorical variables into dummy/indicator variables\n",
                "df_final = pd.get_dummies(df, columns=['Department', 'salary'], drop_first=True)\n",
                "\n",
                "# Define Features (X) and Target (y)\n",
                "X = df_final.drop('left', axis=1)\n",
                "y = df_final['left']\n",
                "\n",
                "# Train-Test Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "print(f\"Training set size: {X_train.shape}\")\n",
                "print(f\"Test set size: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Building & Evaluation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 Logistic Regression (Baseline)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr_model = LogisticRegression(max_iter=1000)\n",
                "lr_model.fit(X_train, y_train)\n",
                "lr_pred = lr_model.predict(X_test)\n",
                "\n",
                "print(\"Logistic Regression Evaluation:\")\n",
                "print(classification_report(y_test, lr_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Random Forest Classifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_model.fit(X_train, y_train)\n",
                "rf_pred = rf_model.predict(X_test)\n",
                "\n",
                "print(\"Random Forest Evaluation:\")\n",
                "print(classification_report(y_test, rf_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 XGBoost Classifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
                "xgb_model.fit(X_train, y_train)\n",
                "xgb_pred = xgb_model.predict(X_test)\n",
                "\n",
                "print(\"XGBoost Evaluation:\")\n",
                "print(classification_report(y_test, xgb_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Comparison & Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plotting Feature Importance for the Random Forest Model\n",
                "feat_importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
                "plt.figure(figsize=(10, 6))\n",
                "feat_importances.nlargest(10).plot(kind='barh', color='teal')\n",
                "plt.title('Top 10 Important Features Driving Attrition')\n",
                "plt.xlabel('Importance Score')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC-AUC Comparison\n",
                "models = [lr_model, rf_model, xgb_model]\n",
                "model_names = ['Logistic Regression', 'Random Forest', 'XGBoost']\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "for model, name in zip(models, model_names):\n",
                "    y_prob = model.predict_proba(X_test)[:, 1]\n",
                "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
                "    auc = roc_auc_score(y_test, y_prob)\n",
                "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.2f})')\n",
                "\n",
                "plt.plot([0, 1], [0, 1], 'k--')\n",
                "plt.xlabel('False Positive Rate')\n",
                "plt.ylabel('True Positive Rate')\n",
                "plt.title('ROC Curve Comparison')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Conclusion\n",
                "- **Best Model**: The Random Forest and XGBoost models significantly outperformed the baseline Logistic Regression model.\n",
                "- **Key Drivers**: `satisfaction_level`, `time_spend_company`, and `number_project` are the most influential factors in predicting employee attrition.\n",
                "- **Business Action**: To reduce attrition, HR should focus on improving satisfaction levels and monitoring workloads (monthly hours and project count) for long-tenured employees."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}